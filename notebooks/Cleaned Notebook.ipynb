{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "**Group 2** \n",
    "Ada Matilde Gige (adgi@itu.dk), Albert Schiffer (albsc@itu.dk), Andreas Frederik Flensted Olsen (frao@itu.dk), Timothy Beck (tibe@itu.dk) and Victor Popp Henriksen (vhen@itu.dk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from PIL import Image \n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "from os import walk #Used for getting all the filenames from a given directory !!!!!MAYBE NOT NECESSARY!!!!!\n",
    "import glob #For finding specific file types\n",
    "\n",
    "%run -i ../fyp2021p3_group00_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading raw datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all images of type .jpg\n",
    "im_file_list2 = glob.glob(\"../data/example_image/*.jpg\")\n",
    "#load all maps of type .png\n",
    "map_file_list2 = glob.glob(\"../data/example_segmentation/*.png\")\n",
    "\n",
    "#im_files = sorted(im_file_list2, key = uniq)\n",
    "im_files = sorted(im_file_list2)\n",
    "len(im_files)\n",
    "print(im_files[0])\n",
    "\n",
    "#map_files = sorted(map_file_list2, key = uniq)\n",
    "map_files = sorted(map_file_list2)\n",
    "len(map_files)         \n",
    "\n",
    "# Loading the true file in\n",
    "true = pd.read_csv('../data/example_ground_truth.csv')\n",
    "# It is already sorted why it is not sorted as the others\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the images into a list and making an ID dictionary\n",
    "Taken from: https://stackoverflow.com/questions/33369832/read-multiple-images-on-a-folder-in-opencv-python/33371454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in all .jpg files from the 'example_image' folder\n",
    "images = [plt.imread(file) for file in im_files]\n",
    "#Load in all .png files from the 'example_segmentation' folder\n",
    "maps = [plt.imread(file) for file in map_files]\n",
    "\n",
    "# Making a dictionary to find the id from the index\n",
    "pic_id = dict()\n",
    "\n",
    "for i in range(150):\n",
    "    pic_id[i] = true['image_id'][i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing a normal image to luminace image\n",
    "Making an image as the segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tolum(image):\n",
    "    '''A function that takes a pictures filename, the picture must be two colored'''\n",
    "    image = Image.open(image).convert('L')\n",
    "    imagenp = np.asarray(image)\n",
    "    return image , imagenp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image , imagenp = tolum('circle.png')\n",
    "\n",
    "plt.imshow(imagenp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asymmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function that finds the center of a picture and meassures the assymmetri\n",
    "\n",
    "def assymmetry(mapID):\n",
    "    mask = maps[mapID]\n",
    "    \n",
    "    borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "    up, down, left, right = max(borders[0]), min(borders[0]), min(borders[1]), max(borders[1])\n",
    "    center = ((left + right)//2, (up+down) //2) # Tuple with the coordinates for the center of the lesion\n",
    "    \n",
    "    difference = 0\n",
    "    \n",
    "    for i in range(18):\n",
    "        borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "        left, right = min(borders[1]), max(borders[1])\n",
    "        \n",
    "        \n",
    "        radiusdiff = (center[0]-left) - (right-center[0])\n",
    "        difference += radiusdiff**2\n",
    "        mask = transform.rotate(mask, 10, center = center)\n",
    "    return difference/areas[mapID]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asymmetry = pd.read_csv(\"../data/features/assymmetry.csv\", names = ['asymmetry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asymmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This cell block loads in the images as imageobjects and resizes them. Afterwards they are being appended\n",
    "to a list to store the new image objects'''\n",
    "\n",
    "images = []\n",
    "for file in im_files:\n",
    "    im = Image.open(file)\n",
    "    im = im.resize((800,500), resample=1) \n",
    "    images.append(im)\n",
    "    \n",
    "\n",
    "maps = []\n",
    "\n",
    "for file in map_files:\n",
    "    ma = Image.open(file)\n",
    "    ma = ma.resize((800,500), resample=1)\n",
    "    maps.append(ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_segmentation(list_of_images, list_of_corresponding_masks): #lists with resized and resampled images\n",
    "    '''this function takes the 2 lists as input, the one list with images, and the other with its corresponding masks (both resized)\n",
    "    For each masked image, it performs a felzensvalb algorithim, to compute the segmentation of the mole. The segmentation is \n",
    "    normalized (divided by the totalt number of pixels in the mole), and afterwards put into the dataframe as a feature.\n",
    "    '''\n",
    "    segmentation = {}\n",
    "    \n",
    "    for i in range(len(list_of_images)): #the file list\n",
    "        img1 = list_of_images[i]\n",
    "        print(img1)\n",
    "\n",
    "        img2 = list_of_corresponding_masks[i]\n",
    "\n",
    "        img2.paste(img1, (0,0), mask = img2) \n",
    "\n",
    "        segments_fz = felzenszwalb(img2, scale=8, sigma=1, min_size=10)\n",
    "\n",
    "        number_of_segments = len(np.unique(segments_fz))\n",
    "\n",
    "        normalized_segmentation = round(number_of_segments/(np.sum(list_of_corresponding_masks[i])),7)\n",
    "\n",
    "        segmentation[i] = normalized_segmentation\n",
    "    \n",
    "    return segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "#felz = color_segmentation(images, maps) \n",
    "\n",
    "''' Exported as a csv file to avoid future run time\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To see what is going on inside the loop, is a cutout for only 1 picture in this block of code\n",
    "\n",
    "'''\n",
    "\n",
    "img1 = images[0]\n",
    "img2 = maps[0]\n",
    "img2.paste(img1, (0,0), mask = img2) \n",
    "segments_fz = felzenszwalb(img2, scale=8, sigma=1, min_size=10)\n",
    "number_of_segments = len(np.unique(segments_fz))\n",
    "normalized_segmentation = round(number_of_segments/(np.sum(maps[0])),7)\n",
    "plt.imshow(mark_boundaries(img2, segments_fz))\n",
    "print('pixels in mask divided by area of mask = ', normalized_segmentation)\n",
    "#segmenation[images[i]] = normalized_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt(\"../data/features/segmentation.csv\", list(felz.values()), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Border\n",
    "### Area and perimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the area and perimeter of all images. \n",
    "\n",
    "areas = []\n",
    "peris = []\n",
    "for i in maps:\n",
    "    area, perimiter = measure_area_perimeter(i)\n",
    "    areas.append(areas)\n",
    "    peris.append(perimiter)\n",
    "    \n",
    "# Adding them to a file, so they don't have to be calculated each time\n",
    "\n",
    "#np.savetxt(\"../data/features/perimeter.csv\", peris, delimiter=\",\")\n",
    "#np.savetxt(\"../data/features/area.csv\", areas, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = np.genfromtxt('../data/features/areas.csv', delimiter=',')\n",
    "perimeter = np.genfromtxt('../data/features/perimeter.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area and perimeter scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot(area, perimeter):\n",
    "    # Define the size of the figure\n",
    "    fig = plt.figure(figsize=(4, 3))\n",
    "    # Set axes, that you want to work with:\n",
    "    axes = fig.add_axes([0, 0, 1, 1]) # left, bottom, width, height (range 0 to 1)\n",
    "    # actually plot the data:\n",
    "    axes.scatter(area, perimeter, label = 'Data', edgecolors='white')\n",
    "    axes.set_title('Area and perimeter')\n",
    "    axes.set_xlabel('Area')\n",
    "    axes.set_ylabel('Perimeter')\n",
    "    #axes.legend(loc='upper left'); axes.set_xlabel(data); axes.set_ylabel(data); axes.set_title('Scatter plot');\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot(areas, perimeter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perimeter divided by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the perimiter divided by area feature\n",
    "\n",
    "pa = []\n",
    "for i in range(150): \n",
    "    pa.append(perimeter[i]/areas[i])\n",
    "    \n",
    "# Making a file with the perimeter divided by area feature\n",
    "#np.savetxt(\"../data/features/perimeterdivarea.csv\", areas, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = np.genfromtxt('../data/features/perimeterdivarea.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a histogram for the perimeter/area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(pa, bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All features in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true['unhealthy'] = 0\n",
    "\n",
    "for i in range(150):\n",
    "    if true['melanoma'][i] == 1 or true['seborrheic_keratosis'][i] == 1:\n",
    "        true['unhealthy'][i] = 1\n",
    "\n",
    "areas = pd.read_csv(\"../data/features/areas.csv\", names = ['area'])\n",
    "perimeter = pd.read_csv(\"../data/features/perimeter.csv\", names = ['perimeter'])\n",
    "pa = pd.read_csv('../data/features/perimeterdivarea.csv', names = ['peri/area'])\n",
    "asymmetry = pd.read_csv(\"../data/features/assymmetry.csv\", names = ['asymmetry'])\n",
    "segmentation = pd.read_csv(\"../data/features/segmentation.csv\", names = ['color segmentation/area'])\n",
    "\n",
    "true['asymmetry'] = asymmetry\n",
    "true['area'] = areas\n",
    "true['perimeter'] = perimeter\n",
    "true['peri/area'] = pa\n",
    "true['color segmentation/area'] = segmentation\n",
    "allfeatures = true\n",
    "        \n",
    "allfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the features\n",
    "\n",
    "onlyfeatures = allfeatures[['area','perimeter', 'asymmetry', 'peri/area', 'color segmentation/area']]\n",
    "sns.boxplot(data=onlyfeatures, width=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features\n",
    "\n",
    "#Fit scaler on our data\n",
    "scaler = preprocessing.StandardScaler().fit(onlyfeatures)\n",
    "\n",
    "#Apply to data itself\n",
    "normfeatures = scaler.transform(onlyfeatures)\n",
    "\n",
    "print(normfeatures.mean()) #small number close to 0, round of error\n",
    "print(normfeatures.var())  #equal to 1 \n",
    "sns.boxplot(data=normfeatures, width=0.5,fliersize=5) #we see both negative and positive values, since the mean is 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normfeatures = pd.DataFrame(normfeatures, columns = ['area','perimeter', 'asymmetry', 'peri/area', 'color segmentation/area'])\n",
    "\n",
    "# Look at values per class\n",
    "normfeatures['unhealthy'] = allfeatures['unhealthy']\n",
    "\n",
    "\n",
    "\n",
    "sns.pairplot(normfeatures, hue=\"unhealthy\", size=3,diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data before feature selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Some noisy data not correlated\n",
    "noise = np.random.RandomState(42).uniform(0, 0.1, size=(normfeatures.shape[0], 20))\n",
    "\n",
    "# Add the noisy data to the informative features\n",
    "X = np.hstack((normfeatures[['area', 'perimeter','asymmetry', 'peri/area', 'color segmentation/area']], noise))\n",
    "y = normfeatures['unhealthy']\n",
    "\n",
    "# Split dataset to select feature and evaluate the classifier\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "        X, y, stratify=y, random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_dev, y_dev, stratify=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate feature selection with mutual information for feature scoring\n",
    "selector = SelectKBest(mutual_info_classif, k=4)\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "scores = selector.scores_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features that had good scores on training set\n",
    "X_train1 = X_train[:, [0,3]]\n",
    "X_train2 = selector.transform(X_train)\n",
    "\n",
    "# Train a classifier\n",
    "knn1 = KNeighborsClassifier(n_neighbors=1) # other hyperparameters possible\n",
    "knn1trained = knn1.fit(X_train2, y_train)\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn2trained = knn2.fit(X_train2, y_train)\n",
    "\n",
    "tree1 = DecisionTreeClassifier() # various hyperparameters\n",
    "tree1trained = tree1.fit(X_train2, y_train)\n",
    "\n",
    "svm1 = svm.SVC()\n",
    "svmtrained = svm1.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the same features as before\n",
    "X_val1 = X_val[:, [0,3]]\n",
    "X_val2 = selector.transform(X_val)\n",
    "\n",
    "y_val_knn1 = knn1trained.predict(X_val2)\n",
    "y_val_knn2 = knn2trained.predict(X_val2)\n",
    "y_val_svm1 = svmtrained.predict(X_val2)\n",
    "y_val_tree = tree1trained.predict(X_val2)\n",
    "\n",
    "# Simple accuracy\n",
    "print(np.sum(y_val_knn1 == y_val) / np.size(y_val) * 100)\n",
    "print(np.sum(y_val_knn2 == y_val) / np.size(y_val) * 100)\n",
    "print(np.sum(y_val_svm1 == y_val) / np.size(y_val) * 100)\n",
    "print(np.sum(y_val_tree == y_val) / np.size(y_val) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
