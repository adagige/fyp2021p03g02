{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "**Group 2** \n",
    "Ada Matilde Gige (adgi@itu.dk), Albert Schiffer (albsc@itu.dk), Andreas Frederik Flensted Olsen (frao@itu.dk), Timothy Beck (tibe@itu.dk) and Victor Popp Henriksen (vhen@itu.dk)\n",
    "\n",
    "Created: 2021-04-06\n",
    "\n",
    "Last modified: 2021-04-22\n",
    "\n",
    "Link to repo: https://github.com/adagige/fyp2021p03g02.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage import transform\n",
    "from PIL import Image \n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import glob #For finding specific file types\n",
    "\n",
    "%run -i ../fyp2021p3_group00_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running or watching code?\n",
    "\n",
    "### If you are interested in only watching the code set the constant run to False, if you want to run the code set the constant to True\n",
    "\n",
    "When watching the code some files will be loaded, but it is feature files which are already made by the code in the Notebook and then saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading raw datafiles\n",
    "Inspiration from: https://stackoverflow.com/questions/33369832/read-multiple-images-on-a-folder-in-opencv-python/33371454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load all images of type .jpg\n",
    "im_file_list2 = glob.glob(\"../data/example_image/*.jpg\")\n",
    "#load all maps of type .png\n",
    "map_file_list2 = glob.glob(\"../data/example_segmentation/*.png\")\n",
    "\n",
    "#load external images \n",
    "im_file_liste = glob.glob(\"../data/external_data/resized_images/*.jpg\")\n",
    "#Load external maps\n",
    "map_file_liste = glob.glob(\"../data/external_data/resized_masks/*.png\")\n",
    "\n",
    "#im_files = sorted(im_file_list2, key = uniq)\n",
    "im_files = sorted(im_file_list2)\n",
    "len(im_files)\n",
    "\n",
    "#map_files = sorted(map_file_list2, key = uniq)\n",
    "map_files = sorted(map_file_list2)\n",
    "len(map_files)\n",
    "\n",
    "#im_files = sorted(im_file_list2, key = uniq)\n",
    "im_filese = sorted(im_file_liste)\n",
    "len(im_filese)\n",
    "\n",
    "#map_files = sorted(map_file_list2, key = uniq)\n",
    "map_filese = sorted(map_file_liste)\n",
    "len(map_filese)    \n",
    "\n",
    "\n",
    "\n",
    "# Loading the true file in\n",
    "true1 = pd.read_csv('../data/example_ground_truth.csv')\n",
    "true2 = pd.read_csv('../data/external_data/resized_ISIC-2017_Training_Part3_GroundTruth.csv')\n",
    "\n",
    "true = pd.concat([true1, true2], ignore_index=True)\n",
    "# It is already sorted why it is not sorted as the others\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the images into a list and making an ID dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for file in im_files:\n",
    "    im = Image.open(file)\n",
    "    im = im.resize((800,500), resample=1) \n",
    "    images.append(im)\n",
    "\n",
    "for file in im_filese:\n",
    "    im = Image.open(file)\n",
    "    images.append(im)\n",
    "\n",
    "maps = []\n",
    "\n",
    "for file in map_files:\n",
    "    ma = Image.open(file)\n",
    "    ma = ma.resize((800,500), resample=1)\n",
    "    maps.append(ma)\n",
    "\n",
    "for file in map_filese:\n",
    "    ma = Image.open(file)\n",
    "    maps.append(ma)\n",
    "\n",
    "\n",
    "# Making a dictionary to find the id from the index\n",
    "pic_id = dict()\n",
    "\n",
    "for i in range(150):\n",
    "    pic_id[i] = true['image_id'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "We used the ABC features to classify the features of melanoma and not melanoma marks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asymetry\n",
    "The asymetry is meassured by finding the center of the image, measuring the distance to the border on each side and comparing the two, the difference was squared to prevent negative number and added to the constant `difference`. Then the image was rotated 5 degrees and the measurement was done once again, the image was rotated 36 times. After the rotation the difference was divided by the area of the lesion to normalize the meassurement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function that finds the center of a picture and meassures the asymmetri\n",
    "\n",
    "def asymmetry(mapID):\n",
    "    mask = np.array(maps[mapID])\n",
    "    \n",
    "    borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "    up, down, left, right = max(borders[0]), min(borders[0]), min(borders[1]), max(borders[1])\n",
    "    center = ((left + right)//2, (up+down) //2) # Tuple with the coordinates for the center of the lesion\n",
    "    \n",
    "    difference = 0\n",
    "    \n",
    "    for i in range(36):\n",
    "        borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "        left, right = min(borders[1]), max(borders[1])\n",
    "        \n",
    "        radiusdiff = (center[0]-left) - (right-center[0])\n",
    "        difference += radiusdiff**2\n",
    "        mask = transform.rotate(mask, 5, center = center)\n",
    "    return difference/area[mapID]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran all images through the function via the lines of code below and saved the output to a file to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a list with all asymmetry values in it and then savin it.\n",
    "if run:\n",
    "    asymmetrylist = []\n",
    "\n",
    "    for i in range(300):\n",
    "        asymmetrylist.append(asymmetry(i))\n",
    "\n",
    "    np.savetxt(\"../data/features/asymmetry36.csv\", asymmetrylist, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing how the asymetry function works (simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 10))\n",
    "\n",
    "mask = np.array(maps[4])\n",
    "\n",
    "borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "up, down, left, right = max(borders[0]), min(borders[0]), min(borders[1]), max(borders[1])\n",
    "center = ((left + right)//2, (up+down) //2) # Tuple with the coordinates for the center of the lesion\n",
    "\n",
    "difference = 0\n",
    "\n",
    "for i in range(4):\n",
    "    borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "    left, right = min(borders[1]), max(borders[1])\n",
    "   \n",
    "    \n",
    "    axes[i].imshow(mask, cmap = 'gray')\n",
    "    axes[i].scatter(center[0], center[1], s=25, c='red', marker='o')\n",
    "   # axes[i].show()\n",
    "    \n",
    "    radiusdiff = (center[0]-left) - (right-center[0])\n",
    "    difference += radiusdiff**2\n",
    "    mask = transform.rotate(mask, 45, center = center)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Border"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the regularity of the border the ration perimeter divided by area was used. The area and perimeter ratio has shown great results in other studies, Fikrle and Pizinger 2007. \n",
    "https://groups.inf.ed.ac.uk/vision/MCDONAGH/related%20work/literature/digital%20computer%20analysis%20of%20dermatoscopical%20images%20-%20Fikrle%20Pizinger%20-%20March%202006.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area and perimeter\n",
    "To find the area and perimeter we used the function from Veronicka with the morphology.disk() set to 5.\n",
    "We tried different values of morphology.disk() but 5 was found to the the best meassurement for the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run: \n",
    "    #Loading the maps in as plt files to be used to find the area an perimiter.\n",
    "\n",
    "    #load all maps of type .png\n",
    "    map_file_area = glob.glob(\"../data/example_segmentation_resize/*.png\")\n",
    "\n",
    "    #Load external maps\n",
    "    map_filee_area = glob.glob(\"../data/external_data/resized_masks/*.png\")\n",
    "\n",
    "\n",
    "    map_files_area = sorted(map_file_area)\n",
    "\n",
    "    map_filese_area = sorted(map_filee_area)   \n",
    "\n",
    "\n",
    "    mapsarea = []\n",
    "\n",
    "    for file in map_files_area:\n",
    "        im = plt.imread(file)\n",
    "        mapsarea.append(im)\n",
    "\n",
    "    for file in map_filese_area:\n",
    "        im = plt.imread(file)\n",
    "        mapsarea.append(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run: \n",
    "    # Finding the area and perimeter of all images. \n",
    "    '''With the use of morphology.disk(5)'''\n",
    "\n",
    "\n",
    "    areas = []\n",
    "    peris = []\n",
    "    for i in mapsarea:\n",
    "        area, perimiter = measure_area_perimeter(i)\n",
    "        areas.append(area)\n",
    "        peris.append(perimiter)\n",
    "\n",
    "    # Adding them to a file, so they don't have to be calculated each time\n",
    "\n",
    "    #np.savetxt(\"../data/features/perimeter5.csv\", peris, delimiter=\",\")\n",
    "    #np.savetxt(\"../data/features/area5.csv\", areas, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area and perimeter scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run: \n",
    "    area = np.genfromtxt('../data/features/area5.csv', delimiter=',')\n",
    "    perimeter = np.genfromtxt('../data/features/perimeter5.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot(area, perimeter):\n",
    "    # Define the size of the figure\n",
    "    fig = plt.figure(figsize=(4, 3))\n",
    "    # Set axes, that you want to work with:\n",
    "    axes = fig.add_axes([0, 0, 1, 1]) # left, bottom, width, height (range 0 to 1)\n",
    "    # actually plot the data:\n",
    "    axes.scatter(area, perimeter, label = 'Data', edgecolors='white')\n",
    "    axes.set_title('Area and perimeter')\n",
    "    axes.set_xlabel('Area')\n",
    "    axes.set_ylabel('Perimeter')\n",
    "    #axes.legend(loc='upper left'); axes.set_xlabel(data); axes.set_ylabel(data); axes.set_title('Scatter plot');\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot(area, perimeter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perimeter divided by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    #making the perimiter divided by area feature\n",
    "    pa = []\n",
    "    for i in range(300): \n",
    "        pa.append(perimeter5[i]/areas5[i])\n",
    "\n",
    "    # Making a file with the perimeter divided by area feature\n",
    "    #np.savetxt(\"../data/features/perimeterdivarea5.csv\", pa, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run: \n",
    "    pa = np.genfromtxt('../data/features/perimeterdivarea5.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram with the perimeter/area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(pa, bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_segmentation(list_of_images, list_of_corresponding_masks): #lists with resized and resampled images\n",
    "    '''this function takes the 2 lists as input, the one list with images, and the other with its corresponding masks (both resized)\n",
    "    For each masked image, it performs a felzensvalb algorithim, to compute the segmentation of the mole. The segmentation is \n",
    "    normalized (divided by the totalt number of pixels in the mole), and afterwards put into the dataframe as a feature.\n",
    "    '''\n",
    "    segmentation = []\n",
    "    \n",
    "    for i in range(len(list_of_images)): #the file list\n",
    "        img1 = list_of_images[i]\n",
    "\n",
    "        img2 = list_of_corresponding_masks[i]\n",
    "\n",
    "        img2.paste(img1, (0,0), mask = img2) \n",
    "\n",
    "        segments_fz = felzenszwalb(img2, scale=8, sigma=1, min_size=10)\n",
    "\n",
    "        number_of_segments = len(np.unique(segments_fz))\n",
    "\n",
    "        normalized_segmentation = round(number_of_segments/(np.sum(list_of_corresponding_masks[i])),7)\n",
    "\n",
    "        segmentation.append(normalized_segmentation)\n",
    "    \n",
    "    return segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run: \n",
    "    #call the function\n",
    "    felz = color_segmentation(images, maps) \n",
    "\n",
    "    ''' Exported as a csv file to avoid future run time\n",
    "    '''\n",
    "\n",
    "    #np.savetxt(\"../data/features/segmentation.csv\", felz, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To see what is going on inside the loop, a cutout of only 1 picture is made in this block of code\n",
    "'''\n",
    "if not run: \n",
    "    img1 = images[0].copy()\n",
    "    img2 = maps[0].copy()\n",
    "    img2.paste(img1, (0,0), mask = img2) \n",
    "    segments_fz = felzenszwalb(img2, scale=8, sigma=1, min_size=10)\n",
    "    number_of_segments = len(np.unique(segments_fz))\n",
    "    normalized_segmentation = round(number_of_segments/(np.sum(maps[0])),7)\n",
    "    plt.imshow(mark_boundaries(img2, segments_fz))\n",
    "    print('pixels in mask divided by area of mask = ', normalized_segmentation)\n",
    "    #segmenation[images[i]] = normalized_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing features\n",
    "All test images were drawn by hand in Paint in black and white. Afterwards they were converted to Luminance pictures. The features were tested on the converted pictures, to see how the features behaved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asym(mask, area):\n",
    "    '''Function to find the asymmetry of test features, the only difference from the original asymmetry is that the area is a \n",
    "    parameter'''\n",
    "\n",
    "    borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "    up, down, left, right = max(borders[0]), min(borders[0]), min(borders[1]), max(borders[1])\n",
    "    center = ((left + right)//2, (up+down) //2) # Tuple with the coordinates for the center of the lesion\n",
    "    \n",
    "    difference = 0\n",
    "    \n",
    "    for i in range(36):\n",
    "        borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "        left, right = min(borders[1]), max(borders[1])\n",
    "        \n",
    "        \n",
    "        radiusdiff = (center[0]-left) - (right-center[0])\n",
    "        difference += radiusdiff**2\n",
    "        mask = transform.rotate(mask, 5, center = center)\n",
    "        \n",
    "    return difference/area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run: \n",
    "    circle = plt.imread('../data/test_pictures/circleL.png')\n",
    "    irregular = plt.imread('../data/test_pictures/irregularL.png')\n",
    "    irregular2 = plt.imread('../data/test_pictures/irregular2L.png')\n",
    "    irregular3 = plt.imread('../data/test_pictures/irregular3L.png')\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\n",
    "\n",
    "    axes[0][0].imshow(circle, cmap = 'gray')\n",
    "    axes[0][0].set_title(label = 'Circle')\n",
    "    axes[0][1].imshow(irregular, cmap = 'gray')\n",
    "    axes[0][1].set_title('Irregular 1')\n",
    "    axes[1][0].imshow(irregular2, cmap = 'gray')\n",
    "    axes[1][0].set_title('Irregular 2')\n",
    "    axes[1][1].imshow(irregular3, cmap = 'gray')\n",
    "    axes[1][1].set_title('Irregular 3')\n",
    "\n",
    "\n",
    "    area1, perimeter1 = measure_area_perimeter(circle)\n",
    "    area2, perimeter2 = measure_area_perimeter(irregular)\n",
    "    area3, perimeter3 = measure_area_perimeter(irregular2)\n",
    "    area4, perimeter4 = measure_area_perimeter(irregular3)\n",
    "\n",
    "\n",
    "    print('The perimeter/area is:','circle', round(perimeter1/area1, 3), 'irregular', round(perimeter2/area2, 3), 'irregular2', \n",
    "          round(perimeter3/area3,3), 'irregular3', round(perimeter4/area4, 3))\n",
    "\n",
    "\n",
    "\n",
    "    asym1 = asym(circle, area1)\n",
    "    asym2 = asym(irregular, area2)\n",
    "    asym3 = asym(irregular2, area3)\n",
    "    asym4 = asym(irregular3, area4)\n",
    "\n",
    "    print('The asymetry is:','circle', round(asym1, 3), 'irregular', round(asym2,3), 'irregular2', round(asym3,3),\n",
    "          'irregular3', round(asym4,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All features in one dataframe with true values\n",
    "All the features are gathered in one dataframe. To save time each feature is loaded from their respective file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = pd.read_csv(\"../data/features/area5.csv\", names = ['area'])\n",
    "perimeter = pd.read_csv(\"../data/features/perimeter5.csv\", names = ['perimeter'])\n",
    "pa = pd.read_csv('../data/features/perimeterdivarea5.csv', names = ['peri/area'])\n",
    "asymmetry = pd.read_csv(\"../data/features/asymmetry36.csv\", names = ['asymmetry'])\n",
    "segmentation = pd.read_csv(\"../data/features/segmentation.csv\", names = ['color segmentation/area'])\n",
    "\n",
    "true['asymmetry'] = asymmetry\n",
    "true['area'] = areas\n",
    "true['perimeter'] = perimeter\n",
    "true['peri/area'] = pa\n",
    "true['color segmentation/area'] = segmentation\n",
    "\n",
    "allfeatures = true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data\n",
    "We decided to scale the data by using the StadardScaler() from sklearn but only on a datafram containing the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfeatures = allfeatures[[ 'asymmetry', 'peri/area', 'color segmentation/area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features\n",
    "\n",
    "#Fit scaler on our data\n",
    "scaler = preprocessing.StandardScaler().fit(onlyfeatures)\n",
    "\n",
    "#Apply to data itself\n",
    "normfeatures = scaler.transform(onlyfeatures)\n",
    "\n",
    "print(normfeatures.mean()) #small number close to 0, round of error\n",
    "print(normfeatures.var())  #equal to 1 \n",
    "sns.boxplot(data=normfeatures, width=0.5,fliersize=5) #we see both negative and positive values, since the mean is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the features\n",
    "The features are plotted with the melanoma/ not melanoma hue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normfeatures = pd.DataFrame(normfeatures, columns = [ 'asymmetry', 'peri/area', 'color segmentation/area'])\n",
    "\n",
    "# Look at values per class\n",
    "normfeatures['melanoma'] = allfeatures['melanoma']\n",
    "\n",
    "\n",
    "p = sns.pairplot(normfeatures, hue=\"melanoma\", height=5,diag_kind=\"hist\", vars = ['asymmetry', 'peri/area', 'color segmentation/area'])\n",
    "\n",
    "p.savefig(\"output.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary classification with k- nearest neighbor, Support vector mahine and decision tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some noisy data not correlated\n",
    "noise = np.random.RandomState(42).uniform(0, 0.1, size=(normfeatures.shape[0], 20))\n",
    "\n",
    "# Add the noisy data to the informative features\n",
    "X = np.hstack((normfeatures[['asymmetry', 'peri/area',  'color segmentation/area' ]], noise))\n",
    "y = normfeatures['melanoma']\n",
    "\n",
    "# Split dataset to select feature and evaluate the classifier \n",
    "# Splitting the data in training 70 % (240/300) validation 10% (30) and test 20% (60) \n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "        X, y, stratify=y, random_state=0, test_size = 0.2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_dev, y_dev, stratify=y_dev, test_size = 0.125, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate feature selection with mutual information for feature scoring --> #mutual_info_classif\n",
    "selector = SelectKBest(mutual_info_classif, k=2) #returns an array of scores and of pvalues.\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "scores = selector.scores_ #call the array of scores\n",
    "\n",
    "# Select features that had good scores on training set\n",
    "X_train1 = X_train[:, [0,3]]\n",
    "X_train2 = selector.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classifier\n",
    "#KNearest Neighbours\n",
    "knn1 = KNeighborsClassifier(n_neighbors=10) # other hyperparameters possible, 10 as nearest neighbors seems like the optimal number\n",
    "knn1trained = knn1.fit(X_train2, y_train)\n",
    "#KNearest Neighbours other parameter\n",
    "knn2 = KNeighborsClassifier(n_neighbors=2)\n",
    "knn2trained = knn2.fit(X_train2, y_train)\n",
    "#Decisiontree\n",
    "tree1 = DecisionTreeClassifier(max_depth=2) # various hyperparameters, max depth = 2 from 1. semester\n",
    "tree1trained = tree1.fit(X_train2, y_train)\n",
    "#Support vector machine\n",
    "svm1 = svm.SVC(gamma='scale')\n",
    "svmtrained = svm1.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the same features as before\n",
    "X_val1 = X_val[:, [0,3]]\n",
    "X_val2 = selector.transform(X_val) # .transform --> reduces the array of all scores to only the best scores\n",
    "\n",
    "y_val_knn1 = knn1trained.predict(X_val2)\n",
    "y_val_knn2 = knn2trained.predict(X_val2) \n",
    "y_val_svm1 = svmtrained.predict(X_val2)\n",
    "y_val_tree = tree1trained.predict(X_val2)\n",
    "\n",
    "# Simple accuracy\n",
    "print((np.sum(y_val_knn1 == y_val) / np.size(y_val) * 100), 'KNN with k=10')\n",
    "print((np.sum(y_val_knn2 == y_val) / np.size(y_val) * 100), 'KNN with k=2')\n",
    "print((np.sum(y_val_tree == y_val) / np.size(y_val) * 100), 'Decisiontree with max depth of 2')\n",
    "print((np.sum(y_val_svm1 == y_val) / np.size(y_val) * 100), 'Support vector machine, with rbf kernel and gamma set to (1/#features*Variance)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc1 = roc_auc_score(y_val, y_val_knn1)\n",
    "auc2 = roc_auc_score(y_val, y_val_knn2)\n",
    "auc3 = roc_auc_score(y_val, y_val_svm1)\n",
    "auc4 =roc_auc_score(y_val, y_val_tree)\n",
    "\n",
    "print(auc1, 'KNN with k=10')\n",
    "print(auc2,'KNN with k=2')\n",
    "print(auc3,'Decisiontree with max depth of 2')\n",
    "print(auc4, 'Support vector machine, with rbf kernel and gamma set to (1/#features*Variance)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifiers are not that great, why we look at cross validation instead, because of the rather small dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation with k- nearest neighbor, Support vector mahine and decision tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the data in training 80 % (225/300) and test 25% (75)\n",
    "\n",
    "Xc = normfeatures[['asymmetry', 'peri/area',  'color segmentation/area' ]]\n",
    "\n",
    "yc = normfeatures['melanoma']\n",
    "\n",
    "# Split dataset to select feature and evaluate the classifier\n",
    "X_trainc, X_testc, y_trainc, y_testc = train_test_split(\n",
    "        Xc, yc, stratify=y, random_state=0, test_size = 0.2)\n",
    "\n",
    "\n",
    "X_trainc.shape, X_testc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying with k- nearest neighbor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the most accurate k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot = []\n",
    "for k in range(1,51):\n",
    "    classifier =KNeighborsClassifier(n_neighbors=k) # Firstly the classifier is made\n",
    "# Then it is trained on the training data by using cross validation cv is the number of splits\n",
    "# We crossval our 5 fold to tune parameters and get an estimate of the score.\n",
    "\n",
    "    scoreknn = cross_val_score(classifier, X_trainc,  y_trainc, cv = 5) \n",
    "    toplot.append(scoreknn.mean())\n",
    "\n",
    "\n",
    "plt.plot(toplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNc =KNeighborsClassifier(n_neighbors=8) # Firstly the classifier is made\n",
    "# Then it is trained on the training data by using cross validation cv is the number of splits\n",
    "# We crossval our 5 fold to tune parameters and get an estimate of the score.\n",
    "\n",
    "scoresknn = cross_val_score(KNNc, X_trainc,  y_trainc, cv = 5) \n",
    "predictedknn = cross_val_predict(KNNc, X_trainc,  y_trainc, cv = 5 ) \n",
    "\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scoresknn.mean(), scoresknn.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying with support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SVMc = svm.SVC() # Firstly the classifier is made\n",
    "# Then it is trained on the training data by using cross validation cv is the number of splits\n",
    "\n",
    "scoresSVM = cross_val_score(SVMc, X_trainc,  y_trainc, cv = 5) \n",
    "predictedSVM = cross_val_predict(SVMc, X_trainc,  y_trainc, cv = 5 ) \n",
    "\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scoresSVM.mean(), scoresSVM.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying with decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCc = DecisionTreeClassifier(max_depth=2) # Firstly the classifier is made\n",
    "# Then it is trained on the training data by using cross validation cv is the number of splits\n",
    "\n",
    "scoresDTC = cross_val_score(DTCc, X_trainc,  y_trainc, cv = 5) \n",
    "predictedDTC = cross_val_predict(DTCc, X_trainc,  y_trainc, cv = 5 ) \n",
    "\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scoresDTC.mean(), scoresDTC.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation the classifiers on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_validation(classifier_list, y_true):\n",
    "    validict = {}    \n",
    "    \n",
    "    for model in classifier_list:\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, model[0]).ravel()\n",
    "        specificity = tn / (tn+fn)\n",
    "        sensitivity = tp / (tp+fp)\n",
    "        validict[model[1]] = (specificity,sensitivity)\n",
    "        \n",
    "    return validict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [(predictedknn, 'predicted_knn'), (predictedSVM, 'predicted_SVM'), (predictedDTC, 'predicted_tree')]\n",
    "\n",
    "validict = model_validation(class_list, y_trainc)\n",
    "\n",
    "for i in range(len(validict.keys())):\n",
    "    name = class_list[i][1]\n",
    "    print('{}: with specificity {} and sensitivity {}'.format(name, validict[name][0], validict[name][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a classifier\n",
    "\n",
    "It is clear from the training sets that the classifiers doing best is the k-nearest neighbor and decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set in classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k- nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorestestknn = cross_val_score(KNNc, X_testc,  y_testc, cv = 5) \n",
    "predictedtestknn = cross_val_predict(KNNc, X_testc,  y_testc, cv = 5 )\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scorestestknn.mean(), scorestestknn.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validict = model_validation([(predictedtestknn, 'predicted_test_knn')], y_testc)\n",
    "\n",
    "for i in range(len(validict.keys())):\n",
    "    name = 'predicted_test_knn'\n",
    "    print('{}: with specificity {} and sensitivity {}'.format(name, validict[name][0], validict[name][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorestestDCTc = cross_val_score(DTCc, X_testc,  y_testc, cv = 5) \n",
    "predictedtestDTCc = cross_val_predict(DTCc, X_testc,  y_testc, cv = 5 )\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scorestestDCTc.mean(), scorestestDCTc.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validict = model_validation([(predictedtestDTCc, 'predicted_test_DTCc')], y_testc)\n",
    "\n",
    "for i in range(len(validict.keys())):\n",
    "    name = 'predicted_test_DTCc'\n",
    "    print('{}: with specificity {} and sensitivity {}'.format(name, validict[name][0], validict[name][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the chosen model and the response on changed quality\n",
    "## Load the images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all images of type .jpg (good quality)\n",
    "im_file_good = glob.glob(\"../data/quality_test/good_quality/images/*.jpg\")\n",
    "#load all maps of type .png\n",
    "map_file_good = glob.glob(\"../data/quality_test/good_quality/masks/*.png\")\n",
    "\n",
    "\n",
    "#load all images of type .jpg (bad_quality)\n",
    "im_file_bad = glob.glob(\"../data/quality_test/bad_quality/images/*.jpg\")\n",
    "#load all maps of type .png\n",
    "map_file_bad = glob.glob(\"../data/quality_test/bad_quality/masks/*.png\")\n",
    "\n",
    "\n",
    "im_files_good = sorted(im_file_good)\n",
    "map_files_good = sorted(map_file_good)\n",
    "\n",
    "im_files_bad = sorted(im_file_bad)\n",
    "map_files_bad = sorted(map_file_bad)\n",
    "\n",
    "\n",
    "images_good = []\n",
    "maps_good = []\n",
    "maps_good_area = []\n",
    "\n",
    "for file in im_files_good:\n",
    "    im = Image.open(file)\n",
    "    images_good.append(im)\n",
    "\n",
    "for file in map_files_good:\n",
    "    im = Image.open(file)\n",
    "    maps_good.append(im)\n",
    "\n",
    "# Appending to the area and perimiter form\n",
    "for file in map_files_good:\n",
    "    im = plt.imread(file)\n",
    "    maps_good_area.append(im)\n",
    "\n",
    "# The images of bad quality:\n",
    "\n",
    "images_bad = []\n",
    "maps_bad = [] \n",
    "maps_bad_area = []\n",
    "\n",
    "for file in im_files_bad:\n",
    "    im = Image.open(file)\n",
    "    images_bad.append(im)\n",
    "\n",
    "for file in map_files_bad:\n",
    "    im = Image.open(file)\n",
    "    maps_bad.append(im)\n",
    "\n",
    "\n",
    "# Appending to the area and perimiter form\n",
    "for file in map_files_bad:\n",
    "    im = plt.imread(file)\n",
    "    maps_bad_area.append(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_good = pd.read_csv('../data/quality_test/good_quality/good_quality_ground_truth.csv')\n",
    "true_good = true_good.sort_values(by=['image_id'], ascending=True)\n",
    "\n",
    "true_bad = pd.read_csv('../data/quality_test/bad_quality/bad_quality_ground_truth.csv')\n",
    "true_bad = true_bad.sort_values(by=['image_id'], ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating features for new datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Border\n",
    "#### Using perimeter/area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    area_good = []\n",
    "    perimeter_good = []\n",
    "\n",
    "    '''With the use of morphology.disk(5)'''\n",
    "\n",
    "    for i in maps_good_area:\n",
    "        area, perimeter = measure_area_perimeter(i)\n",
    "        area_good.append(area)\n",
    "        perimeter_good.append(perimeter)\n",
    "\n",
    "    # Adding them to a file, so they don't have to be calculated each time\n",
    "\n",
    "    #np.savetxt(\"../data/features/perimeter_good.csv\", perimeter_good, delimiter=\",\")\n",
    "    #np.savetxt(\"../data/features/area_good.csv\", area_good, delimiter=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run: \n",
    "    area_bad = []\n",
    "    perimeter_bad = []\n",
    "\n",
    "    '''With the use of morphology.disk(5)'''\n",
    "\n",
    "    for i in maps_bad_area:\n",
    "        area, perimeter = measure_area_perimeter(i)\n",
    "        area_bad.append(area)\n",
    "        perimeter_bad.append(perimeter)\n",
    "\n",
    "    # Adding them to a file, so they don't have to be calculated each time\n",
    "\n",
    "    #np.savetxt(\"../data/features/perimeter_bad.csv\", perimeter_bad, delimiter=\",\")\n",
    "    #np.savetxt(\"../data/features/area_bad.csv\", area_bad, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caculating the perimeter divided by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    pa_good = []\n",
    "\n",
    "    for i in range(len(area_good)):\n",
    "        pa_good.append(perimeter_good[i]/area_good[i])\n",
    "\n",
    "    #np.savetxt(\"../data/features/perimeterdivarea_good.csv\", pa_good, delimiter=\",\")\n",
    "    sns.histplot(pa_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    pa_bad = []\n",
    "\n",
    "    for i in range(len(area_bad)):\n",
    "        pa_bad.append(perimeter_bad[i]/area_bad[i])\n",
    "\n",
    "    #np.savetxt(\"../data/features/perimeterdivarea_bad.csv\", pa_bad, delimiter=\",\")\n",
    "\n",
    "    sns.histplot(pa_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asymmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetryGB(mask, area):\n",
    "    \n",
    "    borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "    up, down, left, right = max(borders[0]), min(borders[0]), min(borders[1]), max(borders[1])\n",
    "    center = ((left + right)//2, (up+down) //2) # Tuple with the coordinates for the center of the lesion\n",
    "    \n",
    "    difference = 0\n",
    "    \n",
    "    for i in range(36):\n",
    "        borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "        left, right = min(borders[1]), max(borders[1])\n",
    "        \n",
    "        radiusdiff = (center[0]-left) - (right-center[0])\n",
    "        difference += radiusdiff**2\n",
    "        mask = transform.rotate(mask, 5, center = center)\n",
    "    return difference/area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run: \n",
    "    asymmetry_good = []\n",
    "\n",
    "    for i in range(len(maps_good_area)):\n",
    "        asy = asymmetryGB(maps_good_area[i], area_good[i])\n",
    "        asymmetry_good.append(asy)\n",
    "\n",
    "    #asymmetry_good\n",
    "\n",
    "    np.savetxt(\"../data/features/asymmetry_good.csv\", asymmetry_good, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run: \n",
    "    asymmetry_bad = []\n",
    "\n",
    "    for i in range(len(maps_bad_area)):\n",
    "        asy = asymmetryGB(maps_bad_area[i], area_bad[i])\n",
    "        asymmetry_bad.append(asy)\n",
    "\n",
    "    #asymmetry_bad\n",
    "\n",
    "    np.savetxt(\"../data/features/asymmetry_bad.csv\", asymmetry_bad, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    CS_good = color_segmentation(images_good, maps_good)\n",
    "    np.savetxt(\"../data/features/col_seg_good.csv\", CS_good, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    CS_bad = color_segmentation(images_bad, bad_good)\n",
    "    np.savetxt(\"../data/features/col_seg_bad.csv\", CS_bad, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New features in one dataframe each and scaling and normalising the features\n",
    "\n",
    "### Good quality images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_good = pd.read_csv('../data/features/perimeterdivarea_good.csv', names = ['peri/area'])\n",
    "asymmetry_good = pd.read_csv(\"../data/features/asymmetry_good.csv\", names = ['asymmetry'])\n",
    "segmentation_good = pd.read_csv(\"../data/features/col_seg_good.csv\", names = ['color segmentation/area'])\n",
    "\n",
    "true_good['asymmetry'] = asymmetry_good\n",
    "true_good['peri/area'] = pa_good\n",
    "true_good['color segmentation/area'] = segmentation_good\n",
    "\n",
    "all_good_features = true_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfeatures_good = all_good_features[[ 'asymmetry', 'peri/area', 'color segmentation/area']]\n",
    "\n",
    "# Scaling the features\n",
    "\n",
    "#Fit scaler on our data\n",
    "scaler_good = preprocessing.StandardScaler().fit(onlyfeatures_good)\n",
    "\n",
    "#Apply to data itself\n",
    "normfeatures_good = scaler.transform(onlyfeatures_good)\n",
    "\n",
    "print(normfeatures_good.mean()) #small number close to 0, round of error\n",
    "print(normfeatures_good.var())  #equal to 1 \n",
    "sns.boxplot(data=normfeatures_good, width=0.5,fliersize=5) #we see both negative and positive values, since the mean is 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normfeatures_good = pd.DataFrame(normfeatures_good, columns = [ 'asymmetry', 'peri/area', 'color segmentation/area'])\n",
    "\n",
    "# Look at values per class\n",
    "normfeatures_good['melanoma'] = all_good_features['melanoma']\n",
    "\n",
    "\n",
    "sns.pairplot(normfeatures_good, hue=\"melanoma\", height=5,diag_kind=\"hist\", vars = ['asymmetry', 'peri/area', 'color segmentation/area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad quality images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_bad = pd.read_csv('../data/features/perimeterdivarea_bad.csv', names = ['peri/area'])\n",
    "asymmetry_bad = pd.read_csv(\"../data/features/asymmetry_bad.csv\", names = ['asymmetry'])\n",
    "segmentation_bad = pd.read_csv(\"../data/features/col_seg_bad.csv\", names = ['color segmentation/area'])\n",
    "\n",
    "true_bad['asymmetry'] = asymmetry_bad\n",
    "true_bad['peri/area'] = pa_bad\n",
    "true_bad['color segmentation/area'] = segmentation_bad\n",
    "\n",
    "all_bad_features = true_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfeatures_bad = all_bad_features[[ 'asymmetry', 'peri/area', 'color segmentation/area']]\n",
    "\n",
    "# Scaling the features\n",
    "\n",
    "#Fit scaler on our data\n",
    "scaler_bad = preprocessing.StandardScaler().fit(onlyfeatures_bad)\n",
    "\n",
    "#Apply to data itself\n",
    "normfeatures_bad = scaler.transform(onlyfeatures_bad)\n",
    "\n",
    "print(normfeatures_bad.mean()) #small number close to 0, round of error\n",
    "print(normfeatures_bad.var())  #equal to 1 \n",
    "sns.boxplot(data=normfeatures_bad, width=0.5,fliersize=5) #we see both negative and positive values, since the mean is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normfeatures_bad = pd.DataFrame(normfeatures_bad, columns = [ 'asymmetry', 'peri/area', 'color segmentation/area'])\n",
    "\n",
    "# Look at values per class\n",
    "normfeatures_bad['melanoma'] = all_bad_features['melanoma']\n",
    "\n",
    "\n",
    "sns.pairplot(normfeatures_bad, hue=\"melanoma\", height=5,diag_kind=\"hist\", vars = ['asymmetry', 'peri/area', 'color segmentation/area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the classifier with the different image resolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good image resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_good = normfeatures_good[['asymmetry', 'peri/area',  'color segmentation/area' ]]\n",
    "y_good = normfeatures_good['melanoma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresknn_good = cross_val_score(KNNc, X_good,  y_good, cv = 5) \n",
    "predictedknn_good = cross_val_predict(KNNc, X_good,  y_good, cv = 5 )\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scoresknn_good.mean(), scoresknn_good.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validict_good = model_validation([(predictedknn_good, 'predictedknn_good')], y_good)\n",
    "\n",
    "for i in range(len(validict_good.keys())):\n",
    "    name = 'predictedknn_good'\n",
    "    print('{}: with specificity {} and sensitivity {}'.format(name, validict_good[name][0], validict_good[name][1]))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresDCTc_good = cross_val_score(DTCc, X_good,  y_good, cv = 5) \n",
    "predictedDTCc_good = cross_val_predict(DTCc, X_good,  y_good, cv = 5 )\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scoresDCTc_good.mean(), scoresDCTc_good.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validictDTC_good = model_validation([(predictedDTCc_good, 'predictedDTC_good')], y_good)\n",
    "\n",
    "for i in range(len(validictDTC_good.keys())):\n",
    "    name = 'predictedDTC_good'\n",
    "    print('{}: with specificity {} and sensitivity {}'.format(name, validictDTC_good[name][0], validictDTC_good[name][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad image resolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bad = normfeatures_bad[['asymmetry', 'peri/area',  'color segmentation/area' ]]\n",
    "y_bad = normfeatures_bad['melanoma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresknn_bad = cross_val_score(KNNc, X_bad,  y_bad, cv = 5) \n",
    "predictedknn_bad = cross_val_predict(KNNc, X_bad,  y_bad, cv = 5 )\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scoresknn_bad.mean(), scoresknn_bad.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validict_bad = model_validation([(predictedknn_bad, 'predictedknn_bad')], y_bad)\n",
    "\n",
    "for i in range(len(validict_bad.keys())):\n",
    "    name = 'predictedknn_bad'\n",
    "    print('{}: with specificity {} and sensitivity {}'.format(name, validict_bad[name][0], validict_bad[name][1]))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresDCTc_bad = cross_val_score(DTCc, X_bad,  y_bad, cv = 5) \n",
    "predictedDTCc_bad = cross_val_predict(DTCc, X_bad,  y_bad, cv = 5 )\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scoresDCTc_bad.mean(), scoresDCTc_bad.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validictDTC_bad = model_validation([(predictedDTCc_bad, 'predictedDTC_bad')], y_bad)\n",
    "\n",
    "for i in range(len(validictDTC_bad.keys())):\n",
    "    name = 'predictedDTC_bad'\n",
    "    print('{}: with specificity {} and sensitivity {}'.format(name, validictDTC_bad[name][0], validictDTC_bad[name][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
