{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "**Group 2** \n",
    "Ada Matilde Gige (adgi@itu.dk), Albert Schiffer (albsc@itu.dk), Andreas Frederik Flensted Olsen (frao@itu.dk), Timothy Beck (tibe@itu.dk) and Victor Popp Henriksen (vhen@itu.dk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage import transform\n",
    "from PIL import Image \n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from os import walk #Used for getting all the filenames from a given directory !!!!!MAYBE NOT NECESSARY!!!!!\n",
    "import glob #For finding specific file types\n",
    "\n",
    "%run -i ../fyp2021p3_group00_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading raw datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all images of type .jpg\n",
    "im_file_list2 = glob.glob(\"../data/example_image/*.jpg\")\n",
    "#load all maps of type .png\n",
    "map_file_list2 = glob.glob(\"../data/example_segmentation/*.png\")\n",
    "\n",
    "#load external images \n",
    "im_file_liste = glob.glob(\"../data/external_data/resized_images/*.jpg\")\n",
    "#Load external maps\n",
    "map_file_liste = glob.glob(\"../data/external_data/resized_masks/*.png\")\n",
    "\n",
    "#im_files = sorted(im_file_list2, key = uniq)\n",
    "im_files = sorted(im_file_list2)\n",
    "len(im_files)\n",
    "\n",
    "#map_files = sorted(map_file_list2, key = uniq)\n",
    "map_files = sorted(map_file_list2)\n",
    "len(map_files)\n",
    "\n",
    "#im_files = sorted(im_file_list2, key = uniq)\n",
    "im_filese = sorted(im_file_liste)\n",
    "len(im_filese)\n",
    "\n",
    "#map_files = sorted(map_file_list2, key = uniq)\n",
    "map_filese = sorted(map_file_liste)\n",
    "len(map_filese)    \n",
    "\n",
    "\n",
    "\n",
    "# Loading the true file in\n",
    "true1 = pd.read_csv('../data/example_ground_truth.csv')\n",
    "true2 = pd.read_csv('../data/external_data/resized_ISIC-2017_Training_Part3_GroundTruth.csv')\n",
    "\n",
    "true = pd.concat([true1, true2], ignore_index=True)\n",
    "# It is already sorted why it is not sorted as the others\n",
    "\n",
    "\n",
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These files are made in this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the images into a list and making an ID dictionary\n",
    "Taken from: https://stackoverflow.com/questions/33369832/read-multiple-images-on-a-folder-in-opencv-python/33371454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in all .jpg files from the 'example_image' folder\n",
    "#images = [plt.imread(file) for file in im_files]\n",
    "#Load in all .png files from the 'example_segmentation' folder\n",
    "#maps = [plt.imread(file) for file in map_files]\n",
    "\n",
    "images = []\n",
    "for file in im_files:\n",
    "    im = Image.open(file)\n",
    "    im = im.resize((800,500), resample=1) \n",
    "    images.append(im)\n",
    "    \n",
    "for file in im_filese:\n",
    "    im = Image.open(file)\n",
    "    images.append(im)\n",
    "    \n",
    "maps = []\n",
    "\n",
    "for file in map_files:\n",
    "    ma = Image.open(file)\n",
    "    ma = ma.resize((800,500), resample=1)\n",
    "    maps.append(ma)\n",
    "    \n",
    "for file in map_filese:\n",
    "    ma = Image.open(file)\n",
    "    maps.append(ma)\n",
    "    \n",
    "\n",
    "# Making a dictionary to find the id from the index\n",
    "pic_id = dict()\n",
    "\n",
    "for i in range(150):\n",
    "    pic_id[i] = true['image_id'][i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the resized images to a folder\n",
    "'''\n",
    "\n",
    "for i in range(150):\n",
    "    im = maps[i]\n",
    "    path = '../data/example_segmentation_resize/'\n",
    "    name = str(pic_id[i] + '_segmentation_resized.png')\n",
    "    pathname = path+name\n",
    "    im.save(pathname)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing features\n",
    "Making an image as the segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tolum(image, name):\n",
    "    '''A function that takes a pictures filename, the picture must be two colored'''\n",
    "    img = Image.open(image).convert('L')\n",
    "    img.save(name+'.png')\n",
    "    return name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assym(mask, area):\n",
    "\n",
    "    borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "    up, down, left, right = max(borders[0]), min(borders[0]), min(borders[1]), max(borders[1])\n",
    "    center = ((left + right)//2, (up+down) //2) # Tuple with the coordinates for the center of the lesion\n",
    "    \n",
    "    difference = 0\n",
    "    \n",
    "    for i in range(36):\n",
    "        borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "        left, right = min(borders[1]), max(borders[1])\n",
    "        \n",
    "        \n",
    "        radiusdiff = (center[0]-left) - (right-center[0])\n",
    "        difference += radiusdiff**2\n",
    "        mask = transform.rotate(mask, 5, center = center)\n",
    "        \n",
    "    return difference/area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tolum('../data/test_pictures/irregular2.png', '../data/test_pictures/irregular2L')\n",
    "\n",
    "circle = plt.imread('circleL.png')\n",
    "irregular = plt.imread('../data/test_pictures/irregularL.png')\n",
    "irregular2 = plt.imread('../data/test_pictures/irregular2L.png')\n",
    "\n",
    "\n",
    "area1, perimeter1 = measure_area_perimeter(circle)\n",
    "area2, perimeter2 = measure_area_perimeter(irregular)\n",
    "area3, perimeter3 = measure_area_perimeter(irregular2)\n",
    "\n",
    "\n",
    "print('circle', perimeter1/area1, 'irregular', perimeter2/area2, 'irregular2', perimeter3/area3)\n",
    "\n",
    "assym1 = assym(circle, area1)\n",
    "assym2 = assym(irregular, area2)\n",
    "assym3 = assym(irregular2, area3)\n",
    "\n",
    "print('circle', assym1, 'irregular', assym2, 'irregular2', assym3)\n",
    "\n",
    "plt.imshow(irregular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asymmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function that finds the center of a picture and meassures the assymmetri\n",
    "\n",
    "def assymmetry(mapID):\n",
    "    mask = np.array(maps[mapID])\n",
    "    \n",
    "    borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "    up, down, left, right = max(borders[0]), min(borders[0]), min(borders[1]), max(borders[1])\n",
    "    center = ((left + right)//2, (up+down) //2) # Tuple with the coordinates for the center of the lesion\n",
    "    \n",
    "    difference = 0\n",
    "    \n",
    "    for i in range(36):\n",
    "        borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "        left, right = min(borders[1]), max(borders[1])\n",
    "        \n",
    "        radiusdiff = (center[0]-left) - (right-center[0])\n",
    "        difference += radiusdiff**2\n",
    "        mask = transform.rotate(mask, 5, center = center)\n",
    "    return difference/areas[mapID]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving it to a file \n",
    "\n",
    "asymmetrylist = []\n",
    "\n",
    "for i in range(300):\n",
    "    asymmetrylist.append(assymmetry(i))\n",
    "\n",
    "#np.savetxt(\"../data/features/assymmetry36.csv\", asymmetrylist, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(asymmetrylist, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asymmetry = pd.read_csv(\"../data/features/assymmetry.csv\", names = ['asymmetry'])\n",
    "\n",
    "sns.histplot(asymmetry, bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Border\n",
    "### Area and perimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the maps in as plt files to be used to find the area an perimiter.\n",
    "\n",
    "#load all maps of type .png\n",
    "map_file_area = glob.glob(\"../data/example_segmentation_resize/*.png\")\n",
    "\n",
    "#Load external maps\n",
    "map_filee_area = glob.glob(\"../data/external_data/resized_masks/*.png\")\n",
    "\n",
    "\n",
    "map_files_area = sorted(map_file_area)\n",
    "\n",
    "map_filese_area = sorted(map_filee_area)   \n",
    "\n",
    "\n",
    "mapsarea = []\n",
    "\n",
    "for file in map_files_area:\n",
    "    im = plt.imread(file)\n",
    "    mapsarea.append(im)\n",
    "    \n",
    "for file in map_filese_area:\n",
    "    im = plt.imread(file)\n",
    "    mapsarea.append(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the area and perimeter of all images. \n",
    "'''With the use of morphology.disk(10)'''\n",
    "\n",
    "\n",
    "areas = []\n",
    "peris = []\n",
    "for i in mapsarea:\n",
    "    area, perimiter = measure_area_perimeter(i)\n",
    "    areas.append(area)\n",
    "    peris.append(perimiter)\n",
    "    \n",
    "# Adding them to a file, so they don't have to be calculated each time\n",
    "\n",
    "#np.savetxt(\"../data/features/perimeter10.csv\", peris, delimiter=\",\")\n",
    "#np.savetxt(\"../data/features/area10.csv\", areas, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../fyp2021p3_group00_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area and perimeter scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot(area, perimeter):\n",
    "    # Define the size of the figure\n",
    "    fig = plt.figure(figsize=(4, 3))\n",
    "    # Set axes, that you want to work with:\n",
    "    axes = fig.add_axes([0, 0, 1, 1]) # left, bottom, width, height (range 0 to 1)\n",
    "    # actually plot the data:\n",
    "    axes.scatter(area, perimeter, label = 'Data', edgecolors='white')\n",
    "    axes.set_title('Area and perimeter')\n",
    "    axes.set_xlabel('Area')\n",
    "    axes.set_ylabel('Perimeter')\n",
    "    #axes.legend(loc='upper left'); axes.set_xlabel(data); axes.set_ylabel(data); axes.set_title('Scatter plot');\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot(areas, peris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perimeter divided by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the perimiter divided by area feature\n",
    "\n",
    "pa = []\n",
    "for i in range(300): \n",
    "    pa.append(perimeter5[i]/areas5[i])\n",
    "    \n",
    "# Making a file with the perimeter divided by area feature\n",
    "#np.savetxt(\"../data/features/perimeterdivarea5.csv\", pa, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a histogram for the perimeter/area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(pa, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(pa, bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_segmentation(list_of_images, list_of_corresponding_masks): #lists with resized and resampled images\n",
    "    '''this function takes the 2 lists as input, the one list with images, and the other with its corresponding masks (both resized)\n",
    "    For each masked image, it performs a felzensvalb algorithim, to compute the segmentation of the mole. The segmentation is \n",
    "    normalized (divided by the totalt number of pixels in the mole), and afterwards put into the dataframe as a feature.\n",
    "    '''\n",
    "    segmentation = []\n",
    "    \n",
    "    for i in range(len(list_of_images)): #the file list\n",
    "        img1 = list_of_images[i]\n",
    "\n",
    "        img2 = list_of_corresponding_masks[i]\n",
    "\n",
    "        img2.paste(img1, (0,0), mask = img2) \n",
    "\n",
    "        segments_fz = felzenszwalb(img2, scale=8, sigma=1, min_size=10)\n",
    "\n",
    "        number_of_segments = len(np.unique(segments_fz))\n",
    "\n",
    "        normalized_segmentation = round(number_of_segments/(np.sum(list_of_corresponding_masks[i])),7)\n",
    "\n",
    "        segmentation.append(normalized_segmentation)\n",
    "    \n",
    "    return segmentation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "felz = color_segmentation(images, maps) \n",
    "\n",
    "''' Exported as a csv file to avoid future run time\n",
    "'''\n",
    "\n",
    "#np.savetxt(\"../data/features/segmentation.csv\", felz, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To see what is going on inside the loop, is a cutout for only 1 picture in this block of code\n",
    "'''\n",
    "\n",
    "img1 = images[0]\n",
    "img2 = maps[0]\n",
    "img2.paste(img1, (0,0), mask = img2) \n",
    "segments_fz = felzenszwalb(img2, scale=8, sigma=1, min_size=10)\n",
    "number_of_segments = len(np.unique(segments_fz))\n",
    "normalized_segmentation = round(number_of_segments/(np.sum(maps[0])),7)\n",
    "plt.imshow(mark_boundaries(img2, segments_fz))\n",
    "print('pixels in mask divided by area of mask = ', normalized_segmentation)\n",
    "#segmenation[images[i]] = normalized_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = np.genfromtxt('../data/features/area5.csv', delimiter=',')\n",
    "perimeter = np.genfromtxt('../data/features/perimeter5.csv', delimiter=',')\n",
    "#areas10 = np.genfromtxt('../data/features/area10.csv', delimiter=',')\n",
    "#perimeter10 = np.genfromtxt('../data/features/perimeter10.csv', delimiter=',')\n",
    "\n",
    "#pa = np.genfromtxt('../data/features/perimeterdivarea.csv', delimiter=',')\n",
    "\n",
    "#fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 3))\n",
    "#axes[0].scatter(areas5, perimeter5)\n",
    "#axes[1].scatter(areas10, perimeter10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All features in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true['unhealthy'] = true['melanoma'] + true['seborrheic_keratosis']\n",
    "\n",
    "areas = pd.read_csv(\"../data/features/area5.csv\", names = ['area'])\n",
    "perimeter = pd.read_csv(\"../data/features/perimeter5.csv\", names = ['perimeter'])\n",
    "pa = pd.read_csv('../data/features/perimeterdivarea5.csv', names = ['peri/area'])\n",
    "asymmetry = pd.read_csv(\"../data/features/assymmetry36.csv\", names = ['asymmetry'])\n",
    "segmentation = pd.read_csv(\"../data/features/segmentation.csv\", names = ['color segmentation/area'])\n",
    "\n",
    "true['asymmetry'] = asymmetry\n",
    "true['area'] = areas\n",
    "true['perimeter'] = perimeter\n",
    "true['peri/area'] = pa\n",
    "true['color segmentation/area'] = segmentation\n",
    "\n",
    "allfeatures = true\n",
    "        \n",
    "allfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot = allfeatures[['asymmetry', 'peri/area','color segmentation/area' ,'unhealthy']]\n",
    "\n",
    "sns.pairplot(toplot, hue=\"unhealthy\", size=3,diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the features\n",
    "\n",
    "onlyfeatures = allfeatures[[ 'asymmetry', 'peri/area', 'color segmentation/area']]\n",
    "sns.boxplot(data=onlyfeatures, width=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scaling the features\n",
    "\n",
    "#Fit scaler on our data\n",
    "scaler = preprocessing.StandardScaler().fit(onlyfeatures)\n",
    "\n",
    "#Apply to data itself\n",
    "normfeatures = scaler.transform(onlyfeatures)\n",
    "\n",
    "print(normfeatures.mean()) #small number close to 0, round of error\n",
    "print(normfeatures.var())  #equal to 1 \n",
    "sns.boxplot(data=normfeatures, width=0.5,fliersize=5) #we see both negative and positive values, since the mean is 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### melanoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normfeatures = pd.DataFrame(normfeatures, columns = [ 'asymmetry', 'peri/area', 'color segmentation/area'])\n",
    "\n",
    "# Look at values per class\n",
    "normfeatures['melanoma'] = allfeatures['melanoma']\n",
    "\n",
    "\n",
    "sns.pairplot(normfeatures, hue=\"melanoma\", size=5,diag_kind=\"hist\", vars = ['asymmetry', 'peri/area', 'color segmentation/area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seborrheic_keratosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Look at values per class\n",
    "normfeatures['seborrheic_keratosis'] = allfeatures['seborrheic_keratosis']\n",
    "\n",
    "\n",
    "sns.pairplot(normfeatures, hue=\"seborrheic_keratosis\", size=5,diag_kind=\"hist\", vars = ['asymmetry', 'peri/area', 'color segmentation/area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal classifying "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data before feature selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Some noisy data not correlated\n",
    "noise = np.random.RandomState(42).uniform(0, 0.1, size=(normfeatures.shape[0], 20))\n",
    "\n",
    "# Add the noisy data to the informative features\n",
    "X = np.hstack((normfeatures[['asymmetry', 'peri/area',  'color segmentation/area' ]], noise))\n",
    "y = normfeatures['seborrheic_keratosis']\n",
    "\n",
    "# Split dataset to select feature and evaluate the classifier \n",
    "# Splitting the data in training 70 % (240/300) validation 10% (30) and test 20% (60) \n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "        X, y, stratify=y, random_state=0, test_size = 0.2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_dev, y_dev, stratify=y_dev, test_size = 0.125, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate feature selection with mutual information for feature scoring --> #mutual_info_classif\n",
    "selector = SelectKBest(mutual_info_classif, k=2) #returns an array of scores and of pvalues.\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "scores = selector.scores_ #call the array of scores\n",
    "\n",
    "# Select features that had good scores on training set\n",
    "X_train1 = X_train[:, [0,3]]\n",
    "X_train2 = selector.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classifier\n",
    "#KNearest Neighbours\n",
    "knn1 = KNeighborsClassifier(n_neighbors=10) # other hyperparameters possible, 10 as nearest neighbors seems like the optimal number\n",
    "knn1trained = knn1.fit(X_train2, y_train)\n",
    "#KNearest Neighbours other parameter\n",
    "knn2 = KNeighborsClassifier(n_neighbors=2)\n",
    "knn2trained = knn2.fit(X_train2, y_train)\n",
    "#Decisiontree\n",
    "tree1 = DecisionTreeClassifier(max_depth=2) # various hyperparameters, max depth = 2 from 1. semester\n",
    "tree1trained = tree1.fit(X_train2, y_train)\n",
    "#Support vector machine\n",
    "svm1 = svm.SVC(gamma='scale')\n",
    "svmtrained = svm1.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the same features as before\n",
    "X_val1 = X_val[:, [0,3]]\n",
    "X_val2 = selector.transform(X_val) # .transform --> reduces the array of all scores to only the best scores\n",
    "\n",
    "y_val_knn1 = knn1trained.predict(X_val2)\n",
    "y_val_knn2 = knn2trained.predict(X_val2) \n",
    "y_val_svm1 = svmtrained.predict(X_val2)\n",
    "y_val_tree = tree1trained.predict(X_val2)\n",
    "\n",
    "# Simple accuracy\n",
    "print((np.sum(y_val_knn1 == y_val) / np.size(y_val) * 100), 'KNN with k=10')\n",
    "print((np.sum(y_val_knn2 == y_val) / np.size(y_val) * 100), 'KNN with k=2')\n",
    "print((np.sum(y_val_tree == y_val) / np.size(y_val) * 100), 'Decisiontree with max depth of 2')\n",
    "print((np.sum(y_val_svm1 == y_val) / np.size(y_val) * 100), 'Support vector machine, with rbf kernel and gamma set to (1/#features*Variance)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_knn1 = accuracy_score(y_val, y_val_knn1)\n",
    "acc_knn2 = accuracy_score(y_val, y_val_knn2)\n",
    "acc_svm1 = accuracy_score(y_val, y_val_svm1)\n",
    "acc_tree = accuracy_score(y_val, y_val_tree)\n",
    "\n",
    "print(acc_knn1)\n",
    "print(acc_knn2)\n",
    "print(acc_svm1)\n",
    "print(acc_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc1 = roc_auc_score(y_val, y_val_knn1)\n",
    "auc2 = roc_auc_score(y_val, y_val_knn2)\n",
    "auc3 = roc_auc_score(y_val, y_val_svm1)\n",
    "auc4 =roc_auc_score(y_val, y_val_tree)\n",
    "\n",
    "print(auc1)\n",
    "print(auc2)\n",
    "print(auc3)\n",
    "print(auc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation works best only on melanoma\n",
    "\n",
    "### Before running remember to:\n",
    "1. Scale the data \n",
    "2. Run the normfeature cell with the type (melanoma, keratosis or unhalthy) you want to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the data in training 70 % (240/300) validation 10% (30) and test 20% (60)\n",
    "\n",
    "X = normfeatures[['asymmetry', 'peri/area',  'color segmentation/area' ]]\n",
    "\n",
    "y = normfeatures['melanoma']\n",
    "\n",
    "# Split dataset to select feature and evaluate the classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, random_state=0, test_size = 0.2)\n",
    "\n",
    "\n",
    "X_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying with knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "classifier =KNeighborsClassifier(n_neighbors=8) # Firstly the classifier is made\n",
    "# Then it is trained on the training data by using cross validation cv is the number of splits\n",
    "# We crossval our 5 fold to tune parameters and get an estimate of the score.\n",
    "\n",
    "scoresknn = cross_val_score(classifier, X_train,  y_train, cv = 5) \n",
    "predictedknn = cross_val_predict(classifier, X_train,  y_train, cv = 5 ) \n",
    "\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scoresknn.mean(), scoresknn.std()))\n",
    "\n",
    "\n",
    "#scorestestknn = cross_val_score(classifier, X_test,  y_test, cv = 5) \n",
    "#predictedtestknn = cross_val_predict(classifier, X_test,  y_test, cv = 5 )\n",
    "\n",
    "#print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scorestestknn.mean(), scorestestknn.std()))\n",
    "\n",
    "\n",
    "#metrics.accuracy_score(y_test, predictedtest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = svm.SVC() # Firstly the classifier is made\n",
    "# Then it is trained on the training data by using cross validation cv is the number of splits\n",
    "\n",
    "scores = cross_val_score(classifier, X_train,  y_train, cv = 5) \n",
    "predicted = cross_val_predict(classifier, X_train,  y_train, cv = 5 ) \n",
    "\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "#scorestest = cross_val_score(classifier, X_test,  y_test, cv = 5) \n",
    "#predictedtest = cross_val_predict(classifier, X_test,  y_test, cv = 5 )\n",
    "\n",
    "#print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scorestest.mean(), scorestest.std()))\n",
    "\n",
    "\n",
    "#metrics.accuracy_score(y_test, predictedtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(max_depth=2) # Firstly the classifier is made\n",
    "# Then it is trained on the training data by using cross validation cv is the number of splits\n",
    "\n",
    "scores = cross_val_score(classifier, X_train,  y_train, cv = 5) \n",
    "predicted = cross_val_predict(classifier, X_train,  y_train, cv = 5 ) \n",
    "\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "scorestest = cross_val_score(classifier, X_test,  y_test, cv = 5) \n",
    "predictedtest = cross_val_predict(classifier, X_test,  y_test, cv = 5 )\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scorestest.mean(), scorestest.std()))\n",
    "\n",
    "\n",
    "metrics.accuracy_score(y_test, predictedtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot = []\n",
    "for k in range(1,11):\n",
    "    classifier =KNeighborsClassifier(n_neighbors=k) # Firstly the classifier is made\n",
    "# Then it is trained on the training data by using cross validation cv is the number of splits\n",
    "# We crossval our 5 fold to tune parameters and get an estimate of the score.\n",
    "\n",
    "    scoreknn = cross_val_score(classifier, X_train,  y_train, cv = 5) \n",
    "    toplot.append(scoreknn.mean())\n",
    "\n",
    "\n",
    "plt.plot(toplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "class_list = [(predicted_knn, 'predicted_knn'), (predicted_SVM, 'predicted_SVM'), (predicted_tree, 'predicted_tree')]\n",
    "\n",
    "def model_validation(classifier_list):\n",
    "    validict = {}    \n",
    "    y_true = allfeatures['melanoma'][60:300]\n",
    "    \n",
    "    for model in classifier_list:\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, model[0]).ravel()\n",
    "        specificity = tn / (tn+fn)\n",
    "        sensitivity = tp / (tp+fp)\n",
    "        validict[model[1]] = (specificity, sensitivity)\n",
    "        \n",
    "    return validict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validation(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
